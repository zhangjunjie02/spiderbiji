
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>8. Scrapy爬虫案例实战 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="9.html" />
    
    
    <link rel="prev" href="7.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../">
            
                <a href="../">
            
                    
                    目录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="./">
            
                <a href="./">
            
                    
                    一、Python网络爬虫进阶实战(上)
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="1.html">
            
                <a href="1.html">
            
                    
                    1. Scrapy框架介绍与安装
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="2.html">
            
                <a href="2.html">
            
                    
                    2. Scrapy框架的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="3.html">
            
                <a href="3.html">
            
                    
                    3. Selector选择器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="4.html">
            
                <a href="4.html">
            
                    
                    4. Spider的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="5.html">
            
                <a href="5.html">
            
                    
                    5. Downloader Middleware的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="6.html">
            
                <a href="6.html">
            
                    
                    6. Spider Middleware的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="7.html">
            
                <a href="7.html">
            
                    
                    7. ItemPipeline的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.8" data-path="8.html">
            
                <a href="8.html">
            
                    
                    8. Scrapy爬虫案例实战
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.9" data-path="9.html">
            
                <a href="9.html">
            
                    
                    本周作业
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../week02/">
            
                <a href="../week02/">
            
                    
                    二、Python网络爬虫进阶实战(中)
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../week02/1.html">
            
                <a href="../week02/1.html">
            
                    
                    09. Selenium的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../week02/2.html">
            
                <a href="../week02/2.html">
            
                    
                    10. Selenium爬取淘宝商品
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../week02/3.html">
            
                <a href="../week02/3.html">
            
                    
                    11. MongoDB数据库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../week02/4.html">
            
                <a href="../week02/4.html">
            
                    
                    12. Scrapy框架使用Selenium
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../week02/5.html">
            
                <a href="../week02/5.html">
            
                    
                    13. 代理的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="../week02/6.html">
            
                <a href="../week02/6.html">
            
                    
                    14. 使用代理爬取信息实战
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.7" data-path="../week02/7.html">
            
                <a href="../week02/7.html">
            
                    
                    15. Redis数据库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.8" data-path="../week02/8.html">
            
                <a href="../week02/8.html">
            
                    
                    16. 分布式爬虫原理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.9" data-path="../week02/9.html">
            
                <a href="../week02/9.html">
            
                    
                    17. Scrapy分布式实战
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.10" data-path="../week02/10.html">
            
                <a href="../week02/10.html">
            
                    
                    本周作业
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >8. Scrapy爬虫案例实战</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="8-scrapy&#x722C;&#x866B;&#x6846;&#x67B6;&#x6848;&#x4F8B;&#x5B9E;&#x6218;">8. Scrapy&#x722C;&#x866B;&#x6846;&#x67B6;&#x6848;&#x4F8B;&#x5B9E;&#x6218;</h1>
<ul>
<li><p>&#x4EFB;&#x52A1;&#xFF1A;&#x722C;&#x53D6;&#x817E;&#x8BAF;&#x7F51;&#x4E2D;&#x5173;&#x4E8E;&#x6307;&#x5B9A;&#x6761;&#x4EF6;&#x7684;&#x6240;&#x6709;<code>&#x793E;&#x4F1A;&#x62DB;&#x8058;</code>&#x4FE1;&#x606F;&#xFF0C;&#x641C;&#x7D22;&#x6761;&#x4EF6;&#x4E3A;<code>&#x5317;&#x4EAC;</code>&#x5730;&#x533A;&#xFF0C;<code>Python</code>&#x5173;&#x952E;&#x5B57;&#x7684;&#x5C31;&#x4E1A;&#x5C97;&#x4F4D;,&#x5E76;&#x5C06;&#x4FE1;&#x606F;&#x5B58;&#x50A8;&#x5230;MySql&#x6570;&#x636E;&#x5E93;&#x4E2D;&#x3002;</p>
</li>
<li><p>&#x7F51;&#x5740;&#xFF1A;<a href="https://hr.tencent.com/position.php?keywords=python&amp;lid=2156" target="_blank">https://hr.tencent.com/position.php?keywords=python&amp;lid=2156</a></p>
</li>
<li><p>&#x5B9E;&#x73B0;&#x601D;&#x8DEF;&#xFF1A;&#x9996;&#x5148;&#x722C;&#x53D6;&#x6BCF;&#x9875;&#x7684;&#x62DB;&#x8058;&#x4FE1;&#x606F;&#x5217;&#x8868;&#xFF0C;&#x518D;&#x722C;&#x53D6;&#x5BF9;&#x5E94;&#x7684;&#x62DB;&#x8058;&#x8BE6;&#x60C5;&#x4FE1;&#x606F;</p>
</li>
</ul>
<h4 id="&#x2460;-&#x521B;&#x5EFA;&#x9879;&#x76EE;">&#x2460; &#x521B;&#x5EFA;&#x9879;&#x76EE;</h4>
<ul>
<li>&#x5728;&#x547D;&#x4EE4;&#x884C;&#x7F16;&#x5199;&#x4E0B;&#x9762;&#x547D;&#x4EE4;&#xFF0C;&#x521B;&#x5EFA;&#x9879;&#x76EE;tencent</li>
</ul>
<pre><code>scrapy startproject  tencent
</code></pre><ul>
<li>&#x9879;&#x76EE;&#x76EE;&#x5F55;&#x7ED3;&#x6784;&#xFF1A;</li>
</ul>
<pre><code>tencent
&#x251C;&#x2500;&#x2500; tencent
&#x2502;   &#x251C;&#x2500;&#x2500; __init__.py
&#x2502;   &#x251C;&#x2500;&#x2500; __pycache__
&#x2502;   &#x251C;&#x2500;&#x2500; items.py        # Items&#x7684;&#x5B9A;&#x4E49;&#xFF0C;&#x5B9A;&#x4E49;&#x6293;&#x53D6;&#x7684;&#x6570;&#x636E;&#x7ED3;&#x6784;
&#x2502;   &#x251C;&#x2500;&#x2500; middlewares.py  # &#x5B9A;&#x4E49;Spider&#x548C;DownLoader&#x7684;Middlewares&#x4E2D;&#x95F4;&#x4EF6;&#x5B9E;&#x73B0;&#x3002; 
&#x2502;   &#x251C;&#x2500;&#x2500; pipelines.py    # &#x5B83;&#x5B9A;&#x4E49;Item Pipeline&#x7684;&#x5B9E;&#x73B0;&#xFF0C;&#x5373;&#x5B9A;&#x4E49;&#x6570;&#x636E;&#x7BA1;&#x9053;
&#x2502;   &#x251C;&#x2500;&#x2500; settings.py     # &#x5B83;&#x5B9A;&#x4E49;&#x9879;&#x76EE;&#x7684;&#x5168;&#x5C40;&#x914D;&#x7F6E;
&#x2502;   &#x2514;&#x2500;&#x2500; spiders         # &#x5176;&#x4E2D;&#x5305;&#x542B;&#x4E00;&#x4E2A;&#x4E2A;Spider&#x7684;&#x5B9E;&#x73B0;&#xFF0C;&#x6BCF;&#x4E2A;Spider&#x90FD;&#x6709;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;
&#x2502;       &#x251C;&#x2500;&#x2500; __init__.py
&#x2502;       &#x2514;&#x2500;&#x2500; __pycache__
&#x2514;&#x2500;&#x2500; scrapy.cfg    #Scrapy&#x90E8;&#x7F72;&#x65F6;&#x7684;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#xFF0C;&#x5B9A;&#x4E49;&#x4E86;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x8DEF;&#x5F84;&#x3001;&#x90E8;&#x7F72;&#x76F8;&#x5173;&#x4FE1;&#x606F;&#x7B49;&#x5185;&#x5BB9;
</code></pre><h4 id="&#x2461;-&#x8FDB;&#x5165;tencent&#x9879;&#x76EE;&#x76EE;&#x5F55;&#xFF0C;&#x521B;&#x5EFA;&#x722C;&#x866B;spider&#x7C7B;&#x6587;&#x4EF6;&#xFF08;hr&#x62DB;&#x8058;&#x4FE1;&#x606F;&#xFF09;">&#x2461; &#x8FDB;&#x5165;tencent&#x9879;&#x76EE;&#x76EE;&#x5F55;&#xFF0C;&#x521B;&#x5EFA;&#x722C;&#x866B;spider&#x7C7B;&#x6587;&#x4EF6;&#xFF08;hr&#x62DB;&#x8058;&#x4FE1;&#x606F;&#xFF09;</h4>
<ul>
<li>&#x6267;&#x884C;genspider&#x547D;&#x4EE4;&#xFF0C;&#x7B2C;&#x4E00;&#x4E2A;&#x53C2;&#x6570;&#x662F;Spider&#x7684;&#x540D;&#x79F0;&#xFF0C;&#x7B2C;&#x4E8C;&#x4E2A;&#x53C2;&#x6570;&#x662F;&#x7F51;&#x7AD9;&#x57DF;&#x540D;&#x3002;</li>
</ul>
<pre><code>scrapy genspider hr hr.tencent.com

$ tree 

&#x251C;&#x2500;&#x2500; tencent
&#x2502;   &#x251C;&#x2500;&#x2500; __init__.py
&#x2502;   &#x251C;&#x2500;&#x2500; __pycache__
&#x2502;   &#x2502;   &#x251C;&#x2500;&#x2500; __init__.cpython-36.pyc
&#x2502;   &#x2502;   &#x2514;&#x2500;&#x2500; settings.cpython-36.pyc
&#x2502;   &#x251C;&#x2500;&#x2500; items.py
&#x2502;   &#x251C;&#x2500;&#x2500; middlewares.py
&#x2502;   &#x251C;&#x2500;&#x2500; pipelines.py
&#x2502;   &#x251C;&#x2500;&#x2500; settings.py
&#x2502;   &#x2514;&#x2500;&#x2500; spiders
&#x2502;       &#x251C;&#x2500;&#x2500; __init__.py
&#x2502;       &#x251C;&#x2500;&#x2500; __pycache__
&#x2502;       &#x2502;   &#x2514;&#x2500;&#x2500; __init__.cpython-36.pyc
&#x2502;       &#x2514;&#x2500;&#x2500; hr.py  #&#x5728;spiders&#x76EE;&#x5F55;&#x4E0B;&#x6709;&#x4E86;&#x4E00;&#x4E2A;&#x722C;&#x866B;&#x7C7B;&#x6587;&#x4EF6;hr.py
&#x2514;&#x2500;&#x2500; scrapy.cfg


# hr.py&#x7684;&#x6587;&#x4EF6;&#x4EE3;&#x7801;&#x5982;&#x4E0B;&#xFF1A;

# -*- coding: utf-8 -*-
import scrapy

class HrSpider(scrapy.Spider):
    name = &apos;hr&apos; 
    allowed_domains = [&apos;hr.tencent.com&apos;]
    start_urls = [&apos;https://hr.tencent.com/position.php?keywords=python&amp;lid=2156&apos;]

    def parse(self, response):
        #&#x89E3;&#x6790;&#x5F53;&#x524D;&#x62DB;&#x8058;&#x5217;&#x8868;&#x4FE1;&#x606F;&#x7684;url&#x5730;&#x5740;&#xFF1A;
        detail_urls = response.css(&apos;tr.even a::attr(href),tr.odd a::attr(href)&apos;).extract()
        #&#x904D;&#x5386;url&#x5730;&#x5740;
        for url in detail_urls:
            #fullurl = &apos;http://hr.tencent.com/&apos; + url
            #&#x6784;&#x5EFA;&#x7EDD;&#x5BF9;&#x7684;url&#x5730;&#x5740;&#xFF0C;&#x6548;&#x679C;&#x540C;&#x4E0A;&#xFF08;&#x57DF;&#x540D;&#x52A0;&#x76F8;&#x5BF9;&#x5730;&#x5740;&#xFF09;
            fullurl = response.urljoin(url) 
            print(fullurl)
</code></pre><ul>
<li>&#x6D4B;&#x8BD5;&#x4E00;&#x4E0B;&#x83B7;&#x53D6;&#x7B2C;&#x4E00;&#x9875;&#x7684;&#x62DB;&#x8058;&#x8BE6;&#x60C5;url&#x5730;&#x5740;&#x4FE1;&#x606F;</li>
</ul>
<h4 id="&#x2462;-&#x521B;&#x5EFA;item">&#x2462; &#x521B;&#x5EFA;Item</h4>
<ul>
<li><p>Item&#x662F;&#x4FDD;&#x5B58;&#x722C;&#x53D6;&#x6570;&#x636E;&#x7684;&#x5BB9;&#x5668;&#xFF0C;&#x5B83;&#x7684;&#x4F7F;&#x7528;&#x65B9;&#x6CD5;&#x548C;&#x5B57;&#x5178;&#x7C7B;&#x578B;&#xFF0C;&#x4F46;&#x76F8;&#x6BD4;&#x5B57;&#x5178;&#x591A;&#x4E86;&#x4E9B;&#x4FDD;&#x62A4;&#x673A;&#x5236;&#x3002;</p>
</li>
<li><p>&#x521B;&#x5EFA;Item&#x9700;&#x8981;&#x7EE7;&#x627F;scrapy.Item&#x7C7B;&#xFF0C;&#x5E76;&#x4E14;&#x5B9A;&#x4E49;&#x7C7B;&#x578B;&#x4E3A;scrapy.Field&#x7684;&#x5B57;&#x6BB5;&#xFF1A;</p>
<ul>
<li>&#x804C;&#x4F4D;id&#x53F7;&#xFF0C;&#x540D;&#x79F0;&#x3001;&#x4F4D;&#x7F6E;&#x3001;&#x7C7B;&#x522B;&#x3001;&#x8981;&#x6C42;&#x3001;&#x4EBA;&#x6570;&#x3001;&#x5DE5;&#x4F5C;&#x804C;&#x8D23;&#x3001;&#x5DE5;&#x4F5C;&#x8981;&#x6C42;</li>
</ul>
</li>
<li><p>&#x5177;&#x4F53;&#x4EE3;&#x7801;&#x5982;&#x4E0B;&#xFF1A;&#xFF08;&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x7C7B;&#x540D;&#x4E3A;HrItem&#xFF09;</p>
</li>
</ul>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> scrapy

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TencentItem</span><span class="hljs-params">(scrapy.Item)</span>:</span>
    <span class="hljs-comment"># define the fields for your item here like:</span>
    <span class="hljs-comment"># name = scrapy.Field()</span>
    <span class="hljs-keyword">pass</span>

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">HrItem</span><span class="hljs-params">(scrapy.Item)</span>:</span>
    <span class="hljs-string">&apos;&apos;&apos;
       &#x4EBA;&#x4E8B;&#x62DB;&#x8058;&#x4FE1;&#x606F;&#x5C01;&#x88C5;&#x7C7B;
       &#xFF08;&#x804C;&#x4F4D;id&#x53F7;&#xFF0C;&#x540D;&#x79F0;&#x3001;&#x4F4D;&#x7F6E;&#x3001;&#x7C7B;&#x522B;&#x3001;&#x8981;&#x6C42;&#x3001;&#x4EBA;&#x6570;&#x3001;&#x804C;&#x8D23;&#x548C;&#x8981;&#x6C42;&#xFF09;
    &apos;&apos;&apos;</span>
    table = <span class="hljs-string">&quot;hr&quot;</span>  <span class="hljs-comment">#&#x8868;&#x540D;</span>
    id = scrapy.Field() 
    title = scrapy.Field()
    location = scrapy.Field()
    type = scrapy.Field()
    number = scrapy.Field()
    duty = scrapy.Field()
    requirement = scrapy.Field()
</code></pre>
<h4 id="&#x2463;-&#x89E3;&#x6790;response">&#x2463; &#x89E3;&#x6790;Response</h4>
<ul>
<li><p>&#x5728;hr.py&#x6587;&#x4EF6;&#x4E2D;&#xFF0C;parse()&#x65B9;&#x6CD5;&#x7684;&#x53C2;&#x6570;response&#x662F;start_urls&#x91CC;&#x9762;&#x7684;&#x94FE;&#x63A5;&#x722C;&#x53D6;&#x540E;&#x7684;&#x7ED3;&#x679C;&#x3002;</p>
</li>
<li><p>&#x63D0;&#x53D6;&#x7684;&#x65B9;&#x5F0F;&#x53EF;&#x4EE5;&#x662F;CSS&#x9009;&#x62E9;&#x5668;&#x3001;XPath&#x9009;&#x62E9;&#x5668;&#x6216;&#x8005;&#x662F;re&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x3002;</p>
</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span>
<span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">from</span> tencent.items <span class="hljs-keyword">import</span> HrItem

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">HrSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">&apos;hr&apos;</span>
    allowed_domains = [<span class="hljs-string">&apos;hr.tencent.com&apos;</span>]
    start_urls = [<span class="hljs-string">&apos;https://hr.tencent.com/position.php?keywords=python&amp;lid=2156&apos;</span>]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-comment">#&#x89E3;&#x6790;&#x5F53;&#x524D;&#x62DB;&#x8058;&#x5217;&#x8868;&#x4FE1;&#x606F;&#x7684;url&#x5730;&#x5740;&#xFF1A;</span>
        detail_urls = response.css(<span class="hljs-string">&apos;tr.even a::attr(href),tr.odd a::attr(href)&apos;</span>).extract()
        <span class="hljs-comment">#&#x904D;&#x5386;url&#x5730;&#x5740;</span>
        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> detail_urls:
            <span class="hljs-comment">#fullurl = &apos;http://hr.tencent.com/&apos; + url</span>
            <span class="hljs-comment">#&#x6784;&#x5EFA;&#x7EDD;&#x5BF9;&#x7684;url&#x5730;&#x5740;&#xFF0C;&#x6548;&#x679C;&#x540C;&#x4E0A;&#xFF08;&#x57DF;&#x540D;&#x52A0;&#x76F8;&#x5BF9;&#x5730;&#x5740;&#xFF09;</span>
            fullurl = response.urljoin(url) 
            <span class="hljs-comment">#print(fullurl)</span>
            <span class="hljs-comment"># &#x6784;&#x9020;&#x8BF7;&#x6C42;&#x51C6;&#x5907;&#x722C;&#x53D6;&#x62DB;&#x8058;&#x8BE6;&#x60C5;&#x4FE1;&#x606F;&#xFF0C;&#x5E76;&#x6307;&#x5B9A;&#x7531;parse_page()&#x65B9;&#x6CD5;&#x89E3;&#x6790;&#x56DE;&#x8C03;&#x51FD;&#x6570;</span>
            <span class="hljs-keyword">yield</span> scrapy.Request(url=fullurl,callback=self.parse_page)

        <span class="hljs-comment">#&#x83B7;&#x53D6;&#x4E0B;&#x4E00;&#x9875;&#x7684;url&#x5730;&#x5740;</span>
        next_url = response.css(<span class="hljs-string">&quot;#next::attr(href)&quot;</span>).extract_first()
        <span class="hljs-comment">#&#x5224;&#x65AD;&#x82E5;&#x4E0D;&#x662F;&#x6700;&#x540E;&#x4E00;&#x9875;</span>
        <span class="hljs-keyword">if</span> next_url != <span class="hljs-string">&quot;javascript:;&quot;</span>:
            url = response.urljoin(next_url)
            <span class="hljs-comment">#&#x6784;&#x9020;&#x4E0B;&#x4E00;&#x9875;&#x62DB;&#x8058;&#x5217;&#x8868;&#x4FE1;&#x606F;&#x7684;&#x722C;&#x53D6;</span>
            <span class="hljs-keyword">yield</span> scrapy.Request(url=url,callback=self.parse)

    <span class="hljs-comment"># &#x89E3;&#x6790;&#x8BE6;&#x60C5;&#x9875;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_page</span><span class="hljs-params">(self,response)</span>:</span>
        <span class="hljs-comment">#&#x6784;&#x9020;&#x62DB;&#x8058;&#x4FE1;&#x606F;&#x7684;Item&#x5BB9;&#x5668;&#x5BF9;&#x8C61;</span>
        item = HrItem()
        <span class="hljs-comment"># &#x89E3;&#x6790;id&#x53F7;&#x4FE1;&#x606F;&#xFF0C;&#x5E76;&#x5C01;&#x88C5;&#x5230;Item&#x4E2D;</span>
        item[<span class="hljs-string">&quot;id&quot;</span>] = response.selector.re_first(<span class="hljs-string">&apos;onclick=&quot;applyPosition\(([0-9]+)\);&quot;&apos;</span>)
        <span class="hljs-comment">#&#x6807;&#x9898;</span>
        item[<span class="hljs-string">&quot;title&quot;</span>] = response.css(<span class="hljs-string">&apos;#sharetitle::text&apos;</span>).extract_first()
        <span class="hljs-comment">#&#x4F4D;&#x7F6E;</span>
        item[<span class="hljs-string">&quot;location&quot;</span>] = response.selector.re_first(<span class="hljs-string">&apos;&lt;span class=&quot;lightblue l2&quot;&gt;&#x5DE5;&#x4F5C;&#x5730;&#x70B9;&#xFF1A;&lt;/span&gt;(.*?)&lt;/td&gt;&apos;</span>)
        <span class="hljs-comment">#&#x7C7B;&#x522B;</span>
        item[<span class="hljs-string">&quot;type&quot;</span>] = response.selector.re_first(<span class="hljs-string">&apos;&lt;span class=&quot;lightblue&quot;&gt;&#x804C;&#x4F4D;&#x7C7B;&#x522B;&#xFF1A;&lt;/span&gt;(.*?)&lt;/td&gt;&apos;</span>)
        <span class="hljs-comment">#&#x4EBA;&#x6570;</span>
        item[<span class="hljs-string">&quot;number&quot;</span>] = response.selector.re_first(<span class="hljs-string">&apos;&lt;span class=&quot;lightblue&quot;&gt;&#x62DB;&#x8058;&#x4EBA;&#x6570;&#xFF1A;&lt;/span&gt;([0-9]+)&#x4EBA;&lt;/td&gt;&apos;</span>)
        <span class="hljs-comment">#&#x5DE5;&#x4F5C;&#x804C;&#x8D23;</span>
        duty = response.xpath(<span class="hljs-string">&apos;//table//tr[3]//li/text()&apos;</span>).extract()
        item[<span class="hljs-string">&quot;duty&quot;</span>] = <span class="hljs-string">&apos;&apos;</span>.join(duty)
        <span class="hljs-comment">#&#x5DE5;&#x4F5C;&#x8981;&#x6C42;</span>
        requirement = response.xpath(<span class="hljs-string">&apos;//table//tr[4]//li/text()&apos;</span>).extract()
        item[<span class="hljs-string">&quot;requirement&quot;</span>] = <span class="hljs-string">&apos;&apos;</span>.join(requirement)
        <span class="hljs-comment">#print(item)</span>
        <span class="hljs-comment">#&#x4EA4;&#x7ED9;&#x7BA1;&#x9053;&#x6587;&#x4EF6;</span>
        <span class="hljs-keyword">yield</span> item
</code></pre>
<h4 id="&#x2464;&#x3001;&#x521B;&#x5EFA;&#x6570;&#x636E;&#x5E93;&#x548C;&#x8868;&#xFF1A;">&#x2464;&#x3001;&#x521B;&#x5EFA;&#x6570;&#x636E;&#x5E93;&#x548C;&#x8868;&#xFF1A;</h4>
<ul>
<li>&#x5728;mysql&#x4E2D;&#x521B;&#x5EFA;&#x6570;&#x636E;&#x5E93;<code>mydb</code>&#x548C;&#x6570;&#x636E;&#x8868;<code>hr</code></li>
</ul>
<pre><code class="lang-mysql">CREATE TABLE `hr` (                          
   `id` int(10) unsigned NOT NULL AUTO_INCREMENT,  
   `title` varchar(255) DEFAULT NULL,              
   `location` varchar(32) DEFAULT NULL,                
   `type` varchar(32) DEFAULT NULL,                
   `number` varchar(32) DEFAULT NULL,             
   `duty` text DEFAULT NULL,                
   `requirement` text DEFAULT NULL,               
   PRIMARY KEY (`id`)                              
 ) ENGINE=InnoDB DEFAULT CHARSET=utf8
</code></pre>
<h4 id="&#x2465;&#x3001;&#x4F7F;&#x7528;item-pipeline">&#x2465;&#x3001;&#x4F7F;&#x7528;Item Pipeline</h4>
<ul>
<li>&#x5728;Item&#x7BA1;&#x9053;&#x6587;&#x4EF6;&#x4E2D;&#xFF0C;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;MysqlPipeline&#xFF0C;&#x8D1F;&#x8D23;&#x8FDE;&#x63A5;&#x6570;&#x636E;&#x5E93;&#x5E76;&#x6267;&#x884C;&#x4FE1;&#x606F;&#x5199;&#x5165;&#x64CD;&#x4F5C;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> pymysql

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TencentPipeline</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span><span class="hljs-params">(self, item, spider)</span>:</span>
        <span class="hljs-keyword">return</span> item

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MysqlPipeline</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,host,user,password,database,port)</span>:</span>
        self.host = host
        self.user = user
        self.password = password
        self.database = database
        self.port = port

<span class="hljs-meta">    @classmethod</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">from_crawler</span><span class="hljs-params">(cls,crawler)</span>:</span>
        <span class="hljs-keyword">return</span> cls(
            host = crawler.settings.get(<span class="hljs-string">&quot;MYSQL_HOST&quot;</span>),
            user = crawler.settings.get(<span class="hljs-string">&quot;MYSQL_USER&quot;</span>),
            password = crawler.settings.get(<span class="hljs-string">&quot;MYSQL_PASS&quot;</span>),
            database = crawler.settings.get(<span class="hljs-string">&quot;MYSQL_DATABASE&quot;</span>),
            port = crawler.settings.get(<span class="hljs-string">&quot;MYSQL_PORT&quot;</span>),
        )

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">open_spider</span><span class="hljs-params">(self, spider)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;&#x8D1F;&#x8D23;&#x8FDE;&#x63A5;&#x6570;&#x636E;&#x5E93;&apos;&apos;&apos;</span>
        self.db = pymysql.connect(self.host,self.user,self.password,self.database,charset=<span class="hljs-string">&quot;utf8&quot;</span>,port=self.port)
        self.cursor = self.db.cursor()

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span><span class="hljs-params">(self, item, spider)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;&#x6267;&#x884C;&#x6570;&#x636E;&#x8868;&#x7684;&#x5199;&#x5165;&#x64CD;&#x4F5C;&apos;&apos;&apos;</span>
        <span class="hljs-comment">#&#x7EC4;&#x88C5;sql&#x8BED;&#x53E5;</span>
        data = dict(item)
        keys = <span class="hljs-string">&apos;,&apos;</span>.join(data.keys())
        values=<span class="hljs-string">&apos;,&apos;</span>.join([<span class="hljs-string">&apos;%s&apos;</span>]*len(data))
        sql = <span class="hljs-string">&quot;insert into %s(%s) values(%s)&quot;</span>%(item.table,keys,values)
        <span class="hljs-comment">#&#x6307;&#x5B9A;&#x53C2;&#x6570;&#xFF0C;&#x5E76;&#x6267;&#x884C;sql&#x6DFB;&#x52A0;</span>
        self.cursor.execute(sql,tuple(data.values()))
        <span class="hljs-comment">#&#x4E8B;&#x52A1;&#x63D0;&#x4EA4;</span>
        self.db.commit()
        <span class="hljs-keyword">return</span> item

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">close_spider</span><span class="hljs-params">(self, spider)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;&#x5173;&#x95ED;&#x8FDE;&#x63A5;&#x6570;&#x636E;&#x5E93;&apos;&apos;&apos;</span>
        self.db.close()
</code></pre>
<h4 id="&#x2466;-&#x4FEE;&#x6539;&#x914D;&#x7F6E;&#x6587;&#x4EF6;">&#x2466; &#x4FEE;&#x6539;&#x914D;&#x7F6E;&#x6587;&#x4EF6;</h4>
<ul>
<li><p>&#x6253;&#x5F00;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#xFF1A;settings.py &#x5F00;&#x542F;&#x5E76;&#x914D;&#x7F6E;ITEM_PIPELINES&#x4FE1;&#x606F;&#xFF0C;&#x914D;&#x7F6E;&#x6570;&#x636E;&#x5E93;&#x8FDE;&#x63A5;&#x4FE1;&#x606F;</p>
</li>
<li><p>&#x5F53;&#x6709;CONCURRENT_REQUESTS&#xFF0C;&#x6CA1;&#x6709;DOWNLOAD_DELAY &#x65F6;&#xFF0C;&#x670D;&#x52A1;&#x5668;&#x4F1A;&#x5728;&#x540C;&#x4E00;&#x65F6;&#x95F4;&#x6536;&#x5230;&#x5927;&#x91CF;&#x7684;&#x8BF7;&#x6C42;&#x3002;</p>
</li>
<li>&#x5F53;&#x6709;CONCURRENT_REQUESTS&#xFF0C;&#x6709;DOWNLOAD_DELAY &#x65F6;&#xFF0C;&#x670D;&#x52A1;&#x5668;&#x4E0D;&#x4F1A;&#x5728;&#x540C;&#x4E00;&#x65F6;&#x95F4;&#x6536;&#x5230;&#x5927;&#x91CF;&#x7684;&#x8BF7;&#x6C42;&#x3002;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5FFD;&#x7565;&#x722C;&#x866B;&#x534F;&#x8BAE;</span>
ROBOTSTXT_OBEY = <span class="hljs-keyword">False</span>

<span class="hljs-comment"># &#x5E76;&#x53D1;&#x91CF;</span>
CONCURRENT_REQUESTS = <span class="hljs-number">1</span> 

<span class="hljs-comment">#&#x4E0B;&#x8F7D;&#x5EF6;&#x8FDF;</span>
DOWNLOAD_DELAY = <span class="hljs-number">0</span>

ITEM_PIPELINES = {
    <span class="hljs-comment">#&apos;educsdn.pipelines.EducsdnPipeline&apos;: 300,</span>
    <span class="hljs-string">&apos;educsdn.pipelines.MysqlPipeline&apos;</span>: <span class="hljs-number">301</span>,
}
MYSQL_HOST = <span class="hljs-string">&apos;localhost&apos;</span>
MYSQL_DATABASE = <span class="hljs-string">&apos;mydb&apos;</span>
MYSQL_USER = <span class="hljs-string">&apos;root&apos;</span>
MYSQL_PASS = <span class="hljs-string">&apos;&apos;</span>
MYSQL_PORT = <span class="hljs-number">3306</span>
</code></pre>
<h4 id="&#x2467;&#x3001;&#x8FD0;&#x884C;&#x722C;&#x53D6;&#xFF1A;">&#x2467;&#x3001;&#x8FD0;&#x884C;&#x722C;&#x53D6;&#xFF1A;</h4>
<ul>
<li>&#x6267;&#x884C;&#x5982;&#x4E0B;&#x547D;&#x4EE4;&#x6765;&#x542F;&#x7528;&#x6570;&#x636E;&#x722C;&#x53D6;<pre><code>scrapy crawl hr
</code></pre></li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="7.html" class="navigation navigation-prev " aria-label="Previous page: 7. ItemPipeline的使用">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="9.html" class="navigation navigation-next " aria-label="Next page: 本周作业">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"8. Scrapy爬虫案例实战","level":"1.3.8","depth":2,"next":{"title":"本周作业","level":"1.3.9","depth":2,"path":"week01/9.md","ref":"week01/9.md","articles":[]},"previous":{"title":"7. ItemPipeline的使用","level":"1.3.7","depth":2,"path":"week01/7.md","ref":"week01/7.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"week01/8.md","mtime":"2018-05-23T09:07:54.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2018-06-06T01:59:17.229Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

